{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "import sys, os        \n",
    "sys.path.insert(0, '..')\n",
    "from lib import models, graph, coarsening, utils\n",
    "import numpy as np\n",
    "import time\n",
    "from nips2016 import humantraffic\n",
    "from tensorflow.python import debug as tf_debug\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "np.random.seed(2017) \n",
    "# notification\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "\n",
    "# 配置显存大小\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.4)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "#config = tf.ConfigProto(\n",
    "#         device_count = {'GPU': 0}\n",
    "#     )\n",
    "# sess = tf.Session(config=config)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Graphs.\n",
    "flags.DEFINE_integer('number_edges', 8, 'Graph: minimum number of edges per vertex.')\n",
    "flags.DEFINE_string('metric', 'euclidean', 'Graph: similarity measure (between features).')\n",
    "# TODO: change cgcnn for combinatorial Laplacians.\n",
    "flags.DEFINE_bool('normalized_laplacian', True, 'Graph Laplacian: normalized.')\n",
    "flags.DEFINE_integer('coarsening_levels', 4, 'Number of coarsened graphs.')\n",
    "\n",
    "# Directories.\n",
    "flags.DEFINE_string('dir_data', os.path.join('..', 'data', 'mnist'), 'Directory to store data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from CoreUtils.SendNotification import send_notification\n",
    "from CoreUtils import SendNotification\n",
    "# SendNotification.http_config = '59.66.107.198'\n",
    "SendNotification.http_config = '192.168.34.138'\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('current path is {0}'.format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "def sparse_matrix_element_wise_max(A, B):\n",
    "    BisBigger = A-B\n",
    "    BisBigger.data = np.where(BisBigger.data < 0, 1, 0)\n",
    "    return A - A.multiply(BisBigger) + B.multiply(BisBigger)\n",
    "def grid_graph(m, corners=False):\n",
    "    z = graph.grid(m)\n",
    "    dist, idx = graph.distance_sklearn_metrics(z, k=FLAGS.number_edges, metric=FLAGS.metric)\n",
    "    A = graph.adjacency(dist, idx)\n",
    "\n",
    "    # Connections are only vertical or horizontal on the grid.\n",
    "    # Corner vertices are connected to 2 neightbors only.\n",
    "    if corners:\n",
    "        import scipy.sparse\n",
    "        A = A.toarray()\n",
    "        A[A < A.max()/1.5] = 0\n",
    "        A = scipy.sparse.csr_matrix(A)\n",
    "        print('{} edges'.format(A.nnz))\n",
    "\n",
    "    print(\"{} > {} edges\".format(A.nnz//2, FLAGS.number_edges*m**2//2))\n",
    "    return A\n",
    "\n",
    "t_start = time.process_time()\n",
    "A = grid_graph(32, corners=False)\n",
    "# A = graph.replace_random_edges(A, 0)\n",
    "# graphs, perm = coarsening.coarsen(A, levels=FLAGS.coarsening_levels, self_connections=False)\n",
    "L = [graph.laplacian(A, normalized=True)] # [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "print('Execution time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "# graph.plot_spectrum(L)\n",
    "# del A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment init\n",
    "# DATA_SET_PATH='../../data/lndata'\n",
    "# DATA_SET_PATH='../../data/lndata_filter'\n",
    "DATA_SET_PATH='../../data/bjtaxi'\n",
    "# DATA_SET_PATH='../../data/shanxidata'\n",
    "seq_num = 3\n",
    "t_start = time.process_time()\n",
    "ht = humantraffic.HumanTraffic(DATA_SET_PATH)\n",
    "# train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_bj_data(seq_num)\n",
    "#train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_data(seq_num)\n",
    "train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_bj_data_period_trend(seq_num)\n",
    "\n",
    "# train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_split_ln_data(seq_num)\n",
    "# A1 = A1.astype(np.float32)\n",
    "# A = sparse_matrix_element_wise_max(A, A1)\n",
    "# A = A.astype(np.float32)\n",
    "# L = [graph.laplacian(A1, normalized=True)] # [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "#del A\n",
    "train_data_ = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2]))\n",
    "print('Execution time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "print('train_data shape: ', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels.shape)\n",
    "plt.plot(train_labels[:, 69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "common = {}\n",
    "common['dir_name']       = 'mnist/'\n",
    "common['num_epochs']     = 20\n",
    "common['batch_size']     = 100\n",
    "common['decay_steps']    = train_data.shape[0] / common['batch_size']\n",
    "common['eval_frequency'] = 100\n",
    "common['brelu']          = 'b1relu'\n",
    "common['pool']           = 'mpool1'\n",
    "# C = max(mnist.train.labels) + 1  # number of classes\n",
    "model_perf = utils.model_perf()\n",
    "print(train_data.shape)\n",
    "# Common hyper-parameters for networks with one convolutional layer.\n",
    "common['regularization'] = 0\n",
    "common['dropout']        = 1\n",
    "common['learning_rate']  = 0.015\n",
    "common['decay_rate']     = 0.9\n",
    "common['momentum']       = 0.9\n",
    "common['F']              = [10]\n",
    "common['K']              = [20]\n",
    "common['p']              = [1]\n",
    "common['M']              = [train_data.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 64\n",
    "    params['_nres_layer_count'] = 4\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = train_data.shape[2]\n",
    "    params['model_name'] = 'ResGNN'\n",
    "    #params['model_name'] = 'GNN'\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "                     \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 4\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 6\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 8\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 10\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 12\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 14\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 16\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 18\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 20\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.config.update({\"load_extensions\":{\"notify\":true}})\n",
    "Jupyter.notebook.config.update({\"load_extensions\":{\"theme_toggle\":true}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    name = 'spline_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'spline'\n",
    "    params['K'] = [10]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    send_notification('cnn_graph finished part 2', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    \n",
    "    name = 'chebyshev_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'chebyshev5'\n",
    "    params['K'] = [5]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    send_notification('cnn_graph finished part 3', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.plot(train_target[:, 68, 1])\n",
    "plt.plot(train_pred[:, 68, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.plot(test_target[:, 68, 1])\n",
    "plt.plot(test_pred[:, 68, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
