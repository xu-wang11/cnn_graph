{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "import sys, os        \n",
    "sys.path.insert(0, '..')\n",
    "from lib import models, graph, coarsening, utils\n",
    "import numpy as np\n",
    "import time\n",
    "from nips2016 import humantraffic\n",
    "from tensorflow.python import debug as tf_debug\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "np.random.seed(2017) \n",
    "# notification\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "\n",
    "# 配置显存大小\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.4)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "#config = tf.ConfigProto(\n",
    "#         device_count = {'GPU': 0}\n",
    "#     )\n",
    "# sess = tf.Session(config=config)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Graphs.\n",
    "flags.DEFINE_integer('number_edges', 8, 'Graph: minimum number of edges per vertex.')\n",
    "flags.DEFINE_string('metric', 'euclidean', 'Graph: similarity measure (between features).')\n",
    "# TODO: change cgcnn for combinatorial Laplacians.\n",
    "flags.DEFINE_bool('normalized_laplacian', True, 'Graph Laplacian: normalized.')\n",
    "flags.DEFINE_integer('coarsening_levels', 4, 'Number of coarsened graphs.')\n",
    "\n",
    "# Directories.\n",
    "flags.DEFINE_string('dir_data', os.path.join('..', 'data', 'mnist'), 'Directory to store data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from CoreUtils.SendNotification import send_notification\n",
    "from CoreUtils import SendNotification\n",
    "# SendNotification.http_config = '101.5.97.134'\n",
    "SendNotification.http_config = '192.168.34.138'\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path is /home/csi/Git/HumanFlowPrediction/cnn_graph/nips2016\n"
     ]
    }
   ],
   "source": [
    "print('current path is {0}'.format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646 > 1600 edges\n",
      "Execution time: 0.10s\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "def sparse_matrix_element_wise_max(A, B):\n",
    "    BisBigger = A-B\n",
    "    BisBigger.data = np.where(BisBigger.data < 0, 1, 0)\n",
    "    return A - A.multiply(BisBigger) + B.multiply(BisBigger)\n",
    "def grid_graph(m, corners=False):\n",
    "    z = graph.grid(m)\n",
    "    dist, idx = graph.distance_sklearn_metrics(z, k=FLAGS.number_edges, metric=FLAGS.metric)\n",
    "    A = graph.adjacency(dist, idx)\n",
    "\n",
    "    # Connections are only vertical or horizontal on the grid.\n",
    "    # Corner vertices are connected to 2 neightbors only.\n",
    "    if corners:\n",
    "        import scipy.sparse\n",
    "        A = A.toarray()\n",
    "        A[A < A.max()/1.5] = 0\n",
    "        A = scipy.sparse.csr_matrix(A)\n",
    "        print('{} edges'.format(A.nnz))\n",
    "\n",
    "    print(\"{} > {} edges\".format(A.nnz//2, FLAGS.number_edges*m**2//2))\n",
    "    return A\n",
    "\n",
    "t_start = time.process_time()\n",
    "A = grid_graph(20, corners=False)\n",
    "# A = graph.replace_random_edges(A, 0)\n",
    "# graphs, perm = coarsening.coarsen(A, levels=FLAGS.coarsening_levels, self_connections=False)\n",
    "L = [graph.laplacian(A, normalized=True)] # [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "print('Execution time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "# graph.plot_spectrum(L)\n",
    "# del A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data_samples: 1487\n",
      "Execution time: 0.10s\n",
      "train_data shape:  (1115, 104, 20)\n"
     ]
    }
   ],
   "source": [
    "# experiment init\n",
    "# DATA_SET_PATH='../../data/lndata'\n",
    "# DATA_SET_PATH='../../data/lndata_filter'\n",
    "DATA_SET_PATH='../../data/lndata_street'\n",
    "#DATA_SET_PATH='../../data/bjtaxi'\n",
    "# DATA_SET_PATH='../../data/shanxidata'\n",
    "seq_num = 4\n",
    "t_start = time.process_time()\n",
    "ht = humantraffic.HumanTraffic(DATA_SET_PATH)\n",
    "# train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_bj_data(seq_num)\n",
    "train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_split_ln_data_period(seq_num)\n",
    "# train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_split_ln_data(seq_num)\n",
    "A1 = A1.astype(np.float32)\n",
    "# A = sparse_matrix_element_wise_max(A, A1)\n",
    "# A = A.astype(np.float32)\n",
    "L = [graph.laplacian(A1, normalized=True)] # [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "#del A\n",
    "train_data_ = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2]))\n",
    "print('Execution time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "print('train_data shape: ', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 104, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7e0cd77518>,\n",
       " <matplotlib.lines.Line2D at 0x7f7e0cd776d8>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNQyDJKlhGCRJjf8FZviUdZsy6iwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e136a6898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "plt.plot(train_labels[:, 69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 104, 20)\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "common = {}\n",
    "common['dir_name']       = 'mnist/'\n",
    "common['num_epochs']     = 100\n",
    "common['batch_size']     = 100\n",
    "common['decay_steps']    = train_data.shape[0] / common['batch_size']\n",
    "common['eval_frequency'] = 100\n",
    "common['brelu']          = 'b1relu'\n",
    "common['pool']           = 'mpool1'\n",
    "# C = max(mnist.train.labels) + 1  # number of classes\n",
    "model_perf = utils.model_perf()\n",
    "print(train_data.shape)\n",
    "# Common hyper-parameters for networks with one convolutional layer.\n",
    "common['regularization'] = 0\n",
    "common['dropout']        = 1\n",
    "common['learning_rate']  = 0.04\n",
    "common['decay_rate']     = 0.9\n",
    "common['momentum']       = 0.9\n",
    "common['F']              = [10]\n",
    "common['K']              = [20]\n",
    "common['p']              = [1]\n",
    "common['M']              = [train_data.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN architecture\n",
      "  input: M_0 = 104\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 104 * 10 / 1 = 1040\n",
      "    weights: F_0 * F_1 * K_1 = 1 * 10 * 20 = 200\n",
      "    biases: F_1 = 10\n",
      "  layer 2: logits (softmax)\n",
      "    representation: M_2 = 104\n",
      "    weights: M_1 * M_2 = 1040 * 104 = 108160\n",
      "    biases: M_2 = 104\n",
      "dict_keys(['conv_init/weights:0', 'conv_init/filter/transpose_2:0', 'conv_init/activation/Relu:0', 'residual_layer_0/sublayer0/weights:0', 'residual_layer_0/sublayer1/weights:0', 'residual_layer_0/sublayer1/activation2/Relu:0', 'residual_layer_1/sublayer0/weights:0', 'residual_layer_1/sublayer1/weights:0', 'residual_layer_1/sublayer1/activation2/Relu:0', 'residual_layer_2/sublayer0/weights:0', 'residual_layer_2/sublayer1/weights:0', 'residual_layer_2/sublayer1/activation2/Relu:0', 'convN/weights:0', 'convN/filter/transpose_2:0'])\n",
      "step 100 / 1115 (epoch 8.97 / 100):\n",
      "  learning_rate = 1.72e-02, loss_average = 1.45e-04\n",
      "  validation mse: 0.00014 ( 185), f1 (weighted), loss: 1.36e-04\n",
      "  time: 2s (wall 2s)\n",
      "time spend 2.1077768802642822...:\n",
      "\n",
      "step 200 / 1115 (epoch 17.94 / 100):\n",
      "  learning_rate = 6.67e-03, loss_average = 9.93e-05\n",
      "  validation mse: 0.00010 ( 185), f1 (weighted), loss: 1.03e-04\n",
      "  time: 5s (wall 4s)\n",
      "time spend 2.0703694820404053...:\n",
      "\n",
      "step 300 / 1115 (epoch 26.91 / 100):\n",
      "  learning_rate = 2.58e-03, loss_average = 9.04e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.52e-05\n",
      "  time: 7s (wall 7s)\n",
      "time spend 2.0132875442504883...:\n",
      "\n",
      "step 400 / 1115 (epoch 35.87 / 100):\n",
      "  learning_rate = 1.00e-03, loss_average = 8.52e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.22e-05\n",
      "  time: 9s (wall 8s)\n",
      "time spend 1.9756314754486084...:\n",
      "\n",
      "step 500 / 1115 (epoch 44.84 / 100):\n",
      "  learning_rate = 3.88e-04, loss_average = 8.34e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.09e-05\n",
      "  time: 11s (wall 10s)\n",
      "time spend 1.9910991191864014...:\n",
      "\n",
      "step 600 / 1115 (epoch 53.81 / 100):\n",
      "  learning_rate = 1.50e-04, loss_average = 8.33e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.04e-05\n",
      "  time: 13s (wall 12s)\n",
      "time spend 1.9970927238464355...:\n",
      "\n",
      "step 700 / 1115 (epoch 62.78 / 100):\n",
      "  learning_rate = 5.82e-05, loss_average = 8.37e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.02e-05\n",
      "  time: 15s (wall 14s)\n",
      "time spend 2.014913320541382...:\n",
      "\n",
      "step 800 / 1115 (epoch 71.75 / 100):\n",
      "  learning_rate = 2.26e-05, loss_average = 8.26e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.01e-05\n",
      "  time: 18s (wall 17s)\n",
      "time spend 2.022493362426758...:\n",
      "\n",
      "step 900 / 1115 (epoch 80.72 / 100):\n",
      "  learning_rate = 8.74e-06, loss_average = 8.24e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.00e-05\n",
      "  time: 20s (wall 19s)\n",
      "time spend 2.012478828430176...:\n",
      "\n",
      "step 1000 / 1115 (epoch 89.69 / 100):\n",
      "  learning_rate = 3.39e-06, loss_average = 8.34e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.00e-05\n",
      "  time: 22s (wall 21s)\n",
      "time spend 2.0661232471466064...:\n",
      "\n",
      "step 1100 / 1115 (epoch 98.65 / 100):\n",
      "  learning_rate = 1.31e-06, loss_average = 8.19e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.00e-05\n",
      "  time: 24s (wall 23s)\n",
      "time spend 1.998082160949707...:\n",
      "\n",
      "step 1115 / 1115 (epoch 100.00 / 100):\n",
      "  learning_rate = 1.18e-06, loss_average = 8.28e-05\n",
      "  validation mse: 0.00009 ( 185), f1 (weighted), loss: 9.00e-05\n",
      "  time: 25s (wall 23s)\n",
      "time spend 0.40360116958618164...:\n",
      "\n",
      "validation accuracy: peak = 0.00, mean = 0.00\n",
      "train mse: 0.00008 ( 1115), f1 (weighted), loss: 8.28e-05\n",
      "time: 0s (wall 0s)\n",
      "test  mse: 0.00010 ( 187), f1 (weighted), loss: 9.69e-05\n",
      "time: 6s (wall 4s)\n",
      "total time 28.34983801841736 elapse...\n",
      "\n",
      "6.072389285484375 6.5701050113882795\n",
      "train finish...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 32\n",
    "    params['_nres_layer_count'] = 3\n",
    "    params['K'] = [20]\n",
    "    params['_STACK_NUM'] = 1\n",
    "    params['C_0'] = train_data.shape[2]\n",
    "    params['model_name'] = 'ResGNN'\n",
    "    # params['model_name'] = 'GNN'\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    s1 = str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2])))\n",
    "    s2 = str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2])))\n",
    "    print (s1 + ' ' + s2)\n",
    "    print('train finish...\\n') \n",
    "\n",
    "    send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "                     \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 64\n",
    "    params['_nres_layer_count'] = 4\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2              \n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 6\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 8\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 10\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 12\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 14\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 16\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 18\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 20\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.config.update({\"load_extensions\":{\"notify\":true}})\n",
    "Jupyter.notebook.config.update({\"load_extensions\":{\"theme_toggle\":true}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    name = 'spline_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'spline'\n",
    "    params['K'] = [10]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    send_notification('cnn_graph finished part 2', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    \n",
    "    name = 'chebyshev_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'chebyshev5'\n",
    "    params['K'] = [5]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    send_notification('cnn_graph finished part 3', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(train_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.plot(train_target[:, 68, 1])\n",
    "plt.plot(train_pred[:, 68, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.plot(test_target[:, 68, 1])\n",
    "plt.plot(test_pred[:, 68, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
