{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "import sys, os        \n",
    "sys.path.insert(0, '..')\n",
    "from lib import models, graph, coarsening, utils\n",
    "import numpy as np\n",
    "import time\n",
    "from nips2016 import humantraffic\n",
    "from tensorflow.python import debug as tf_debug\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "np.random.seed(2017) \n",
    "# notification\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "\n",
    "# 配置显存大小\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.4)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "#config = tf.ConfigProto(\n",
    "#         device_count = {'GPU': 0}\n",
    "#     )\n",
    "# sess = tf.Session(config=config)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Graphs.\n",
    "flags.DEFINE_integer('number_edges', 8, 'Graph: minimum number of edges per vertex.')\n",
    "flags.DEFINE_string('metric', 'euclidean', 'Graph: similarity measure (between features).')\n",
    "# TODO: change cgcnn for combinatorial Laplacians.\n",
    "flags.DEFINE_bool('normalized_laplacian', True, 'Graph Laplacian: normalized.')\n",
    "flags.DEFINE_integer('coarsening_levels', 4, 'Number of coarsened graphs.')\n",
    "\n",
    "# Directories.\n",
    "flags.DEFINE_string('dir_data', os.path.join('..', 'data', 'mnist'), 'Directory to store data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from CoreUtils.SendNotification import send_notification\n",
    "from CoreUtils import SendNotification\n",
    "# SendNotification.http_config = '59.66.107.198'\n",
    "SendNotification.http_config = '192.168.34.138'\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path is /home/csi/Git/HumanFlowPrediction/cnn_graph/nips2016\n"
     ]
    }
   ],
   "source": [
    "print('current path is {0}'.format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646 > 1600 edges\n",
      "Execution time: 0.10s\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "def sparse_matrix_element_wise_max(A, B):\n",
    "    BisBigger = A-B\n",
    "    BisBigger.data = np.where(BisBigger.data < 0, 1, 0)\n",
    "    return A - A.multiply(BisBigger) + B.multiply(BisBigger)\n",
    "def grid_graph(m, corners=False):\n",
    "    z = graph.grid(m)\n",
    "    dist, idx = graph.distance_sklearn_metrics(z, k=FLAGS.number_edges, metric=FLAGS.metric)\n",
    "    A = graph.adjacency(dist, idx)\n",
    "\n",
    "    # Connections are only vertical or horizontal on the grid.\n",
    "    # Corner vertices are connected to 2 neightbors only.\n",
    "    if corners:\n",
    "        import scipy.sparse\n",
    "        A = A.toarray()\n",
    "        A[A < A.max()/1.5] = 0\n",
    "        A = scipy.sparse.csr_matrix(A)\n",
    "        print('{} edges'.format(A.nnz))\n",
    "\n",
    "    print(\"{} > {} edges\".format(A.nnz//2, FLAGS.number_edges*m**2//2))\n",
    "    return A\n",
    "\n",
    "t_start = time.process_time()\n",
    "A = grid_graph(20, corners=False)\n",
    "# A = graph.replace_random_edges(A, 0)\n",
    "# graphs, perm = coarsening.coarsen(A, levels=FLAGS.coarsening_levels, self_connections=False)\n",
    "L = [graph.laplacian(A, normalized=True)] # [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "print('Execution time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "# graph.plot_spectrum(L)\n",
    "# del A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data_samples: 1487\n",
      "Execution time: 0.05s\n",
      "train_data shape:  (1115, 104, 10)\n"
     ]
    }
   ],
   "source": [
    "# experiment init\n",
    "# DATA_SET_PATH='../../data/lndata'\n",
    "# DATA_SET_PATH='../../data/lndata_filter'\n",
    "DATA_SET_PATH='../../data/lndata_street'\n",
    "#DATA_SET_PATH='../../data/bjtaxi'\n",
    "# DATA_SET_PATH='../../data/shanxidata'\n",
    "seq_num = 4\n",
    "t_start = time.process_time()\n",
    "ht = humantraffic.HumanTraffic(DATA_SET_PATH)\n",
    "# train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_bj_data(seq_num)\n",
    "train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_ln_data_period(seq_num)\n",
    "# train_data, val_data, test_data, train_labels, val_labels, test_labels, A1 = ht.load_split_ln_data(seq_num)\n",
    "A1 = A1.astype(np.float32)\n",
    "# A = sparse_matrix_element_wise_max(A, A1)\n",
    "# A = A.astype(np.float32)\n",
    "L = [graph.laplacian(A1, normalized=True)] # [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "#del A\n",
    "train_data_ = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2]))\n",
    "print('Execution time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "print('train_data shape: ', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 104, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb37d932e10>,\n",
       " <matplotlib.lines.Line2D at 0x7fb37d932fd0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNQyDJKlhGCRJjf8FZviUdZsy6iwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb38022b080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "plt.plot(train_labels[:, 69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 104, 10)\n"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "common = {}\n",
    "common['dir_name']       = 'mnist/'\n",
    "common['num_epochs']     = 100\n",
    "common['batch_size']     = 100\n",
    "common['decay_steps']    = train_data.shape[0] / common['batch_size']\n",
    "common['eval_frequency'] = 100\n",
    "common['brelu']          = 'b1relu'\n",
    "common['pool']           = 'mpool1'\n",
    "# C = max(mnist.train.labels) + 1  # number of classes\n",
    "model_perf = utils.model_perf()\n",
    "print(train_data.shape)\n",
    "# Common hyper-parameters for networks with one convolutional layer.\n",
    "common['regularization'] = 0\n",
    "common['dropout']        = 1\n",
    "\n",
    "common['decay_rate']     = 0.9\n",
    "common['momentum']       = 0.9\n",
    "common['F']              = [10]\n",
    "common['K']              = [20]\n",
    "common['p']              = [1]\n",
    "common['M']              = [train_data.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN architecture\n",
      "  input: M_0 = 104\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 104 * 10 / 1 = 1040\n",
      "    weights: F_0 * F_1 * K_1 = 1 * 10 * 20 = 200\n",
      "    biases: F_1 = 10\n",
      "  layer 2: logits (softmax)\n",
      "    representation: M_2 = 104\n",
      "    weights: M_1 * M_2 = 1040 * 104 = 108160\n",
      "    biases: M_2 = 104\n",
      "dict_keys(['conv_init/weights:0', 'conv_init/filter/Reshape_3:0', 'conv_init/activation/Relu:0', 'residual_layer_0/sublayer0/weights:0', 'residual_layer_0/sublayer1/weights:0', 'residual_layer_0/sublayer1/activation2/Relu:0', 'residual_layer_1/sublayer0/weights:0', 'residual_layer_1/sublayer1/weights:0', 'residual_layer_1/sublayer1/activation2/Relu:0', 'residual_layer_2/sublayer0/weights:0', 'residual_layer_2/sublayer1/weights:0', 'residual_layer_2/sublayer1/activation2/Relu:0', 'convN/weights:0', 'convN/filter/Reshape_3:0'])\n",
      "step 100 / 1115 (epoch 8.97 / 100):\n",
      "  learning_rate = 1.29e-02, loss_average = 7.34e+05\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 22s (wall 38s)\n",
      "time spend 36.05172157287598...:\n",
      "\n",
      "step 200 / 1115 (epoch 17.94 / 100):\n",
      "  learning_rate = 5.00e-03, loss_average = 1.95e+01\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 43s (wall 74s)\n",
      "time spend 36.76869297027588...:\n",
      "\n",
      "step 300 / 1115 (epoch 26.91 / 100):\n",
      "  learning_rate = 1.94e-03, loss_average = 1.40e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 65s (wall 111s)\n",
      "time spend 36.29355001449585...:\n",
      "\n",
      "step 400 / 1115 (epoch 35.87 / 100):\n",
      "  learning_rate = 7.51e-04, loss_average = 1.33e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 90s (wall 156s)\n",
      "time spend 45.84894680976868...:\n",
      "\n",
      "step 500 / 1115 (epoch 44.84 / 100):\n",
      "  learning_rate = 2.91e-04, loss_average = 1.32e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 114s (wall 201s)\n",
      "time spend 44.12839984893799...:\n",
      "\n",
      "step 600 / 1115 (epoch 53.81 / 100):\n",
      "  learning_rate = 1.13e-04, loss_average = 1.33e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 135s (wall 238s)\n",
      "time spend 37.72395730018616...:\n",
      "\n",
      "step 700 / 1115 (epoch 62.78 / 100):\n",
      "  learning_rate = 4.37e-05, loss_average = 1.35e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 156s (wall 275s)\n",
      "time spend 36.29939126968384...:\n",
      "\n",
      "step 800 / 1115 (epoch 71.75 / 100):\n",
      "  learning_rate = 1.69e-05, loss_average = 1.34e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 176s (wall 311s)\n",
      "time spend 36.31427764892578...:\n",
      "\n",
      "step 900 / 1115 (epoch 80.72 / 100):\n",
      "  learning_rate = 6.55e-06, loss_average = 1.32e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 196s (wall 347s)\n",
      "time spend 36.28538203239441...:\n",
      "\n",
      "step 1000 / 1115 (epoch 89.69 / 100):\n",
      "  learning_rate = 2.54e-06, loss_average = 1.35e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 217s (wall 384s)\n",
      "time spend 36.31023383140564...:\n",
      "\n",
      "step 1100 / 1115 (epoch 98.65 / 100):\n",
      "  learning_rate = 9.84e-07, loss_average = 1.31e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 238s (wall 420s)\n",
      "time spend 36.30349922180176...:\n",
      "\n",
      "step 1115 / 1115 (epoch 100.00 / 100):\n",
      "  learning_rate = 8.85e-07, loss_average = 1.34e-02\n",
      "  validation mse: 0.01258 ( 185), f1 (weighted), loss: 1.26e-02\n",
      "  time: 242s (wall 426s)\n",
      "time spend 6.420221567153931...:\n",
      "\n",
      "validation accuracy: peak = 0.01, mean = 0.01\n",
      "train mse: 0.01333 ( 1115), f1 (weighted), loss: 1.33e-02\n",
      "time: 3s (wall 2s)\n",
      "test  mse: 0.01421 ( 187), f1 (weighted), loss: 1.42e-02\n",
      "time: 1s (wall 1s)\n",
      "total time 435.2053475379944 elapse...\n",
      "\n",
      "77.23463448069576\n",
      "79.74286386061588\n",
      "train finish...\n",
      "\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 110] Connection timed out>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1318\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 936\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f98023393a6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train finish...\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0msend_notification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_graph finished part 1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnn_grpah'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/csi/Git/HumanFlowPrediction/CoreUtils/SendNotification.py\u001b[0m in \u001b[0;36msend_notification\u001b[0;34m(title, message)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhttp_config\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':5405/sendnotify'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/csi/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 110] Connection timed out>"
     ]
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    params['filter'] = 'chebyshev5' # fourier\n",
    "    # params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 32\n",
    "    params['_nres_layer_count'] = 3\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = train_data.shape[2]\n",
    "    params['model_name'] = 'ResGNN'\n",
    "    params['learning_rate'] = 0.03\n",
    "    #params['model_name'] = 'GNN'\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "                     \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['learning_rate'] = 0.01\n",
    "    params['_nres_layer_count'] = 4\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 6\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 8\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 10\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 12\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 14\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 16\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 18\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "if True:\n",
    "    \n",
    "    # sess = tf.Session(config=config)\n",
    "    start_time = time.time()\n",
    "    name = 'fgconv_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'fourier'\n",
    "    params['_nfilter'] = 24\n",
    "    params['_nres_layer_count'] = 20\n",
    "    params['K'] = [20]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    end_time = time.time()\n",
    "    print(\"total time {0} elapse...\\n\".format(end_time - start_time))\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    # send_notification('cnn_graph finished part 1', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.config.update({\"load_extensions\":{\"notify\":true}})\n",
    "Jupyter.notebook.config.update({\"load_extensions\":{\"theme_toggle\":true}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    name = 'spline_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'spline'\n",
    "    params['K'] = [10]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    send_notification('cnn_graph finished part 2', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    \n",
    "    name = 'chebyshev_softmax'\n",
    "    params = common.copy()\n",
    "    params['dir_name'] += name\n",
    "    #params['filter'] = 'chebyshev2' # fourier\n",
    "    params['filter'] = 'chebyshev5'\n",
    "    params['K'] = [5]\n",
    "    params['C_0'] = seq_num * 2\n",
    "    train_pred, test_pred =  model_perf.test(models.cgcnn(L, **params), name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "\n",
    "    train_pred, test_pred = ht.reverse_normalize(train_pred), ht.reverse_normalize(test_pred)\n",
    "    train_target, test_target = ht.reverse_normalize(train_labels), ht.reverse_normalize(test_labels)\n",
    "    #\n",
    "    # real_data = np.concatenate(train_labels, test_labels)\n",
    "    # pred_data = np.concatenate(train_pred, test_pred)\n",
    "    print(str(math.sqrt(np.sum((train_target - train_pred) ** 2) / (train_pred.shape[0] * train_pred.shape[1] * train_pred.shape[2]))))\n",
    "    print(str(math.sqrt(np.sum((test_target - test_pred) ** 2) / (test_pred.shape[0] * test_pred.shape[1] * test_pred.shape[2]))))\n",
    "    print('train finish...\\n')\n",
    "    send_notification('cnn_graph finished part 3', 'cnn_grpah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(train_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.plot(train_target[:, 68, 1])\n",
    "plt.plot(train_pred[:, 68, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(15, 10)\n",
    "plt.plot(test_target[:, 68, 1])\n",
    "plt.plot(test_pred[:, 68, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
